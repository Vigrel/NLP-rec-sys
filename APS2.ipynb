{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.glove import Glove\n",
    "from utils.tokenizer import MyTokenizer\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as pxb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = pd.read_csv('data/reviews_content.csv')\n",
    "tokenizer = MyTokenizer(sentence_length=1000, case_sensitive=False)\n",
    "tokenizer.fit(documents.content)\n",
    "\n",
    "glove_vectors = Glove._load_glove_vectors(\"model/glove.6B/glove.6B.300d.txt\")\n",
    "\n",
    "embdd = Glove._get_data_embedding(tokenizer,glove_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_weights = embdd.weight.data  # Shape: (num_embeddings, embedding_dim)\n",
    "\n",
    "num_embeddings, embedding_dim = embedding_weights.shape\n",
    "print(\"Original embedding shape:\", embedding_weights.shape)\n",
    "\n",
    "class EmbeddingAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, reduced_dim):\n",
    "        super(EmbeddingAutoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 250),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(250, reduced_dim)  \n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(reduced_dim, 250),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(250, input_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "reduced_dim = 200 \n",
    "autoencoder = EmbeddingAutoencoder(input_dim=embedding_dim, reduced_dim=reduced_dim)\n",
    "\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=1e-4)\n",
    "\n",
    "dataset = TensorDataset(embedding_weights)\n",
    "data_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in data_loader:\n",
    "        data = batch[0]\n",
    "        encoded, decoded = autoencoder(data)\n",
    "        \n",
    "        loss = criterion(decoded, data)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss / len(data_loader):.4f}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    reduced_embeddings, _ = autoencoder(embedding_weights)\n",
    "\n",
    "print(\"Reduced embedding shape:\", reduced_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_embeddings_np = embedding_weights.numpy()\n",
    "reduced_embeddings_np = reduced_embeddings.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_original = TSNE(n_components=2, random_state=42, perplexity=50, n_jobs=-1)\n",
    "original_embeddings_2d = tsne_original.fit_transform(original_embeddings_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_reduced = TSNE(n_components=2, random_state=42, perplexity=50, n_jobs=-1)\n",
    "reduced_embeddings_2d = tsne_reduced.fit_transform(reduced_embeddings_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_embeddings = np.sum(reduced_embeddings_np**2, axis=1)\n",
    "max_indices = np.argsort(abs_embeddings)[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_original = pd.DataFrame(original_embeddings_2d, columns=[\"x\", \"y\"])\n",
    "df_original = pd.DataFrame(original_embeddings_2d[max_indices], columns=[\"x\", \"y\"])\n",
    "df_original[\"Type\"] = \"Original\"\n",
    "\n",
    "# Reduced embeddings in 2D\n",
    "# df_reduced = pd.DataFrame(reduced_embeddings_2d, columns=[\"x\", \"y\"])\n",
    "df_reduced = pd.DataFrame(reduced_embeddings_2d[max_indices], columns=[\"x\", \"y\"])\n",
    "df_reduced[\"Type\"] = \"Reduced\"\n",
    "\n",
    "# Combine for Plotly visualization\n",
    "df = pd.concat([df_original, df_reduced])\n",
    "\n",
    "# Plot with Plotly\n",
    "fig = px.scatter(df, x=\"x\", y=\"y\", color=\"Type\", title=\"t-SNE Visualization of Original and Reduced Embeddings\", hover_data={'x': False, 'y': False})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"A racing game with mercedes cars\"\n",
    "# query = \"A puzzle game featuring portal and teleportation mechanics\"\n",
    "# query = \"A game that combines elements of horror and educational content\"\n",
    "\n",
    "# documents = pd.read_csv('data/reviews_content.csv')\n",
    "# tokenizer = MyTokenizer(sentence_length=1000, case_sensitive=False)\n",
    "# tokenizer.fit(documents.content)\n",
    "\n",
    "# q_embdd = Glove._get_data_embedding(tokenizer,glove_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(vectors):\n",
    "    vectors = np.array(vectors)\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = []\n",
    "for phrase in documents.content:\n",
    "    tokens = tokenizer(phrase)  \n",
    "    vectors = [q_embdd.weight[token] for token in tokens]\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(vectors)):  \n",
    "            enhanced_embedding, _ = autoencoder(vectors[i])\n",
    "            vectors[i] = mean_pooling(enhanced_embedding.detach().numpy())\n",
    "\n",
    "    sentence_embeddings.append(vectors)\n",
    "documents[\"sentence_embeddings\"] = sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(query)  \n",
    "query_embedding = [q_embdd.weight[token] for token in tokens]\n",
    "with torch.no_grad():\n",
    "    for i in range(len(vectors)):  \n",
    "        enhanced_embedding, _ = autoencoder(query_embedding[i])\n",
    "        query_embedding[i] = mean_pooling(enhanced_embedding.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = np.asarray(query_embedding)\n",
    "sentence_embeddings = np.asarray(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "reduced_query_embedding = F.normalize(torch.from_numpy(np.asarray([query_embedding])), dim=1)\n",
    "reduced_embeddings_normalized = F.normalize(torch.from_numpy(np.asarray(sentence_embeddings)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = F.cosine_similarity(reduced_embeddings_normalized, reduced_query_embedding.unsqueeze(0), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 10\n",
    "top_k_indices = torch.topk(similarities, top_k).indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(documents[\n",
    "        [\n",
    "            \"title\",\n",
    "            \"link\",\n",
    "        ]\n",
    "    ]\n",
    "    .iloc[top_k_indices]\n",
    "    .fillna(\"\")\n",
    "    .to_dict(orient=\"records\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
